{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento del set de datos\n",
    "\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se presenta el preprocesamiento de datos realizado al dataset diabetes.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias y configuraciones iniciales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura del dataset\n",
    "\n",
    "-------------------------\n",
    "\n",
    "Se lee el set de datos crudo para comenzar a realizar el preprocesamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0  Female  80.0             0              1           never  25.19   \n",
       "1  Female  54.0             0              0         No Info  27.32   \n",
       "2    Male  28.0             0              0           never  27.32   \n",
       "3  Female  36.0             0              0         current  23.45   \n",
       "4    Male  76.0             1              1         current  20.14   \n",
       "\n",
       "   HbA1c_level  blood_glucose_level  diabetes  \n",
       "0          6.6                  140         0  \n",
       "1          6.6                   80         0  \n",
       "2          5.7                  158         0  \n",
       "3          5.0                  155         0  \n",
       "4          4.8                  155         0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://github.com/cris21309/tdsp_template_grupo8/blob/master/scripts/data_acquisition/diabetes.csv?raw=true')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza del dataset\n",
    "\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inicia identificando los registros duplicados del dataset, para esto se utiliza el metodo dupplicated de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos duplicados: 3854\n",
      "Porcentaje de datos duplicados: 3.85 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Cantidad de datos duplicados: {df.duplicated().sum()}')\n",
    "print(f'Porcentaje de datos duplicados: {round((df.duplicated().sum()/df.shape)[0] * 100, 2)} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El porcentaje de datos duplicado es muy pequeño por lo tanto se eliminan para no tener problemas en secciones posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continutacion se consulta el numero de datos faltantes, siendo este cero para todas las columnas del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "smoking_history        0\n",
       "bmi                    0\n",
       "HbA1c_level            0\n",
       "blood_glucose_level    0\n",
       "diabetes               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicion de las caracteristicas y etiquetas\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se separan las caracteristicas y las etiquetas, asignadoles la variable X e y respectivamente. Nuestra etiqueta sera la columna \"Diabetes\". Tambien se comprueban la dimension de los arreglos resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones caracteristicas: (96146, 8)\n",
      "Dimensiones etiquetas: (96146,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['diabetes'], axis = 1)\n",
    "y = df['diabetes']\n",
    "print(f'Dimensiones caracteristicas: {X.shape}')\n",
    "print(f'Dimensiones etiquetas: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que tenemos 3 tipos de variables que son, boleanas, númericas y categóricas. Se separan segun su tipo para aplicarle metodos de preprocesamiento segun su conveniencia. Por lo tanto los grupos quedaran de la siguiente manera.\n",
    "\n",
    "* Variables boleanas : hypertension, heart_disease\n",
    "* Variables númericas: age, bmi, HbA1c_level, blood_glucose_level\n",
    "* Variables categóricas: gender, smoking_history\n",
    "\n",
    "Para terminar, se verifica sus dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones variables boleanas: (96146, 2)\n",
      "Dimensiones variables numericas: (96146, 4)\n",
      "Dimensiones varaibles categoricas: (96146, 2)\n"
     ]
    }
   ],
   "source": [
    "bol = ['hypertension', 'heart_disease']\n",
    "num = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "cat = ['gender', 'smoking_history']\n",
    "\n",
    "X_bol = X[bol].values\n",
    "X_num = X[num].values\n",
    "X_cat = X[cat].values\n",
    "\n",
    "print (f'Dimensiones variables boleanas: {X_bol.shape}')\n",
    "print(f'Dimensiones variables numericas: {X_num.shape}')\n",
    "print(f'Dimensiones varaibles categoricas: {X_cat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien se transforma a un arreglo las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones etiquetas: (96146,)\n"
     ]
    }
   ],
   "source": [
    "y =  y.values\n",
    "print(f'Dimensiones etiquetas: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observan los arreglos obtenidos para cada tipo de variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo 6:\n",
      "Variables boleanas: [0 0]\n",
      "Variables numericas: [ 44.    19.31   6.5  200.  ]\n",
      "Variables categoricas: ['Female' 'never']\n",
      "Etiqueta: 1\n",
      "\n",
      "Ejemplo 100:\n",
      "Variables boleanas: [0 0]\n",
      "Variables numericas: [ 38.    27.32   6.   158.  ]\n",
      "Variables categoricas: ['Male' 'never']\n",
      "Etiqueta: 0\n",
      "\n",
      "Ejemplo 5203:\n",
      "Variables boleanas: [0 0]\n",
      "Variables numericas: [ 51.    27.32   3.5  200.  ]\n",
      "Variables categoricas: ['Female' 'No Info']\n",
      "Etiqueta: 0\n",
      "\n",
      "Ejemplo 96117:\n",
      "Variables boleanas: [1 0]\n",
      "Variables numericas: [ 51.    28.67   6.1  145.  ]\n",
      "Variables categoricas: ['Female' 'No Info']\n",
      "Etiqueta: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ind = [6, 100, 5203, 96117]\n",
    "\n",
    "for i in ind:\n",
    "  print(f'Ejemplo {i}:')\n",
    "  print('Variables boleanas:', X_bol[i])\n",
    "  print('Variables numericas:', X_num[i])\n",
    "  print('Variables categoricas:', X_cat[i])\n",
    "  print('Etiqueta:', y[i])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización variables númericas\n",
    "\n",
    "--------------------------------\n",
    "Luego de analizar los resultados obtenidos en la etapa de entendimiento del negocio, se llego a la conclusión de que el metodo apropiado para preprocesar la data era la normalización ya que segun las distribuciones de probabilidad los rangos de los valores eran muy lejanos entre si en la mayoria de casos. Para esto utilzamos la herramienta MinMaxScaler de sickit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))  \n",
    "scaler.fit(X_num)\n",
    "X_num_minmax = scaler.transform(X_num) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observan las transformaciones de los datos luego de aplicar la normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo: 0\n",
      "Original:  [ 80.    25.19   6.6  140.  ]\n",
      "MinMax:  [1.         0.17717087 0.56363636 0.27272727]\n",
      "\n",
      "Ejemplo: 1\n",
      "Original:  [54.   27.32  6.6  80.  ]\n",
      "MinMax:  [0.67467467 0.20203081 0.56363636 0.        ]\n",
      "\n",
      "Ejemplo: 2\n",
      "Original:  [ 28.    27.32   5.7  158.  ]\n",
      "MinMax:  [0.34934935 0.20203081 0.4        0.35454545]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "  print('Ejemplo:', i)\n",
    "  print('Original: ', X_num[i])\n",
    "  print('MinMax: ', X_num_minmax[i])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['min_max_scaler.pkl']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'min_max_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación variables categoricas\n",
    "\n",
    "-----------------------------\n",
    "\n",
    "Dado que tenemos dos variables categoricas, se aplicara el metodo de one-hot encoding para que estas puedan ser utilizadas por un modelo machine learning y poder brindar informacion adicional y mejorar el rendimiento del modelo. Primero se verifica si el numero de asignaciones por variable es viable para aplicar one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores posibles de gender: \t3\n",
      "Valores posibles de smoking_history: \t6\n"
     ]
    }
   ],
   "source": [
    "for var in cat:\n",
    "  print(f'Valores posibles de {var}: \\t{X[var].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez verificado se procede a aplicar OneHotEncoder de scikit-learn, para obtener una transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse_output=False)   \n",
    "enc.fit(X_cat)\n",
    "X_cat_onehot = enc.transform(X_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observan los cambios realizados con one hot encoding a las varaibles categoricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo: 0\n",
      "Original:  ['Female' 'never']\n",
      "One Hot:  [1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "\n",
      "Ejemplo: 1\n",
      "Original:  ['Female' 'No Info']\n",
      "One Hot:  [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Ejemplo: 15\n",
      "Original:  ['Male' 'No Info']\n",
      "One Hot:  [0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Ejemplo: 20\n",
      "Original:  ['Male' 'current']\n",
      "One Hot:  [0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ids = [0, 1, 15, 20]\n",
    "for i in ids:\n",
    "  print('Ejemplo:', i)\n",
    "  print('Original: ', X_cat[i])\n",
    "  print('One Hot: ', X_cat_onehot[i])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guarda el entrenamiento del one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one_hencoder.pkl']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(enc, 'one_hencoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para terminar esta subseccion se concatenan los arreglos con las transformaciones obtenidas, cabe resaltar que para el caso de las variables boleanas no se realizo ninguna transformación ya que no necesitan alguna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96146, 15)\n"
     ]
    }
   ],
   "source": [
    "X_fin = np.concatenate((X_num_minmax, X_bol ,X_cat_onehot),axis=1) \n",
    "print(X_fin.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación del data set en entrenamiento y prueba.\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separa el set de datos en 80% entrenamiento y 20% prueba. Con el fin de prepararlo para ingresar a un modelo para ser entrenado. El conjunto de validación no fue extraido ya que se utilizaran metodos de validacion cruzada mas adelante y por lo tanto sera configurado en ese momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_fin, y, test_size=0.2, random_state=42, stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se obtienen las dimensiones de los datos de entrenamiento y evaluación para las caracteristicas y la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones X_train: (76916, 15)\n",
      "Dimensiones X_test: (19230, 15)\n",
      "Dimensiones y_train: (76916,)\n",
      "Dimensiones y_test: (19230,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimensiones X_train: {X_train.shape}')\n",
    "print(f'Dimensiones X_test: {X_test.shape}')\n",
    "print(f'Dimensiones y_train: {y_train.shape}')\n",
    "print(f'Dimensiones y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se almacenan los arreglos numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('train_test_array.npz', X_train = X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
